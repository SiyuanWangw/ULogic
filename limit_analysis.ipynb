{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "openai.api_key = \"\"\n",
    "\n",
    "\n",
    "def get_GPT4_response(input, temp=1.0, max_tokens=256, logit_dict={}, model=\"gpt-4-0613\"):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                # model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a helpful factual assistant.\" \n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": input\n",
    "                }\n",
    "                ],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temp,\n",
    "                logit_bias=logit_dict\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            sleep_time = 5\n",
    "            print(e, f\"Sleep {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "    # print(completion.usage)\n",
    "    return completion.choices[0].message[\"content\"]\n",
    "\n",
    "def get_davinci3_response(input, temp=1.0, max_tokens=256):\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                # model=\"text-davinci-003\",\n",
    "                model='gpt-3.5-turbo-instruct',\n",
    "                prompt=input,\n",
    "                temperature=temp,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            sleep_time = 30\n",
    "            print(e, f\"Sleep {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "\n",
    "def get_chat_response(inputs_list, temp=0.0, max_tokens=256, logit_dict={}, model=\"gpt-4-0613\"):\n",
    "    while True:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a helpful factual assistant.\" \n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": inputs_list[0]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": inputs_list[1]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": inputs_list[2]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": inputs_list[4]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": inputs_list[2]\n",
    "                },\n",
    "                ],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temp,\n",
    "                logit_bias=logit_dict\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            sleep_time = 5\n",
    "            print(e, f\"Sleep {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "    return completion.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence_to_conclusion_premise(each_rule):\n",
    "    each_rule = each_rule.strip()\n",
    "\n",
    "    assert \":- \" in each_rule\n",
    "    conclusion, premises = each_rule.split(\":- \")\n",
    "    premises_list = premises.split(\"),\")\n",
    "    for m in range(len(premises_list)):\n",
    "        premises_list[m] = premises_list[m].strip()\n",
    "        if m < len(premises_list) - 1:\n",
    "            premises_list[m] = premises_list[m] + \")\"\n",
    "        elif premises_list[m][-1] == \";\" or premises_list[m][-1] == \".\":\n",
    "            premises_list[m] = premises_list[m][:-1]\n",
    "    return conclusion.strip(), premises_list\n",
    "\n",
    "# parsing a premise/conclusion into arguments\n",
    "def argument_parsing(premise, output_rela=False):\n",
    "    premise = premise.strip()\n",
    "    args_type_variable_list = []\n",
    "    if premise.count(\"(\") != 1:\n",
    "        if not output_rela:\n",
    "            return args_type_variable_list\n",
    "        else:\n",
    "            return None, args_type_variable_list   \n",
    "         \n",
    "    rela_end = premise.index(\"(\")\n",
    "    relation = premise[:rela_end]\n",
    "    args_list = [each.strip() for each in premise[rela_end+1:-1].split(\",\")]\n",
    "    for each in args_list:\n",
    "        assert \" \" in each\n",
    "        each_arg_split= each.split()\n",
    "        each_type = \" \".join(each_arg_split[:-1])\n",
    "        each_variable = each_arg_split[-1]\n",
    "        args_type_variable_list.append(each_type + \" \" + each_variable)\n",
    "        \n",
    "    if output_rela:\n",
    "        return relation, args_type_variable_list\n",
    "    else:\n",
    "        return args_type_variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input(each_rule):    \n",
    "    input = \"True or False? Please predict whether the input rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y. \\n\" + \\\n",
    "            \"Output: True. Because Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Input: If Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y. \\n\" + \\\n",
    "            \"Output: False. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_symbolic_critic_input(each_rule):    \n",
    "    input = \"True or False? Please predict whether the input symbolic rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: CanDrive(Person X, Vehicle Y):- Have(Person X, Age Z1), RequireMinimumAge(Vehicle Y, Age Z2), BiggerThan(Age Z1, Age Z2); \\n\" + \\\n",
    "            \"Output: True. Because Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Input: CanAccess(Person X, Plant Y):- BornIn(Person X, Season Z), BloomsIn(Plant Y, Season Z); \\n\" + \\\n",
    "            \"Output: False. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_Think(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be true. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y.\n",
    "Thought: If Person X's age (Z1) is indeed greater than the required age (Z2) to drive Vehicle Y, then logically, Person X meets the age requirement to drive Vehicle Y. \n",
    "Answer: Based on this thought process, the statement is True.\n",
    "Input: If Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y.\n",
    "Thought: The fact that Person X was born in Season Z and Plant Y blooms in Season Z is a coincidence in timing and does not inherently establish a causal or enabling relationship for access. \n",
    "Answer: Based on this thought process, the statement is False.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "\n",
    "def get_affordance_verbalized_critic_input_Think_v2(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Note that the rule need not necessarily but just very likely to be true. \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y.\n",
    "Thought 1: The condition states that Person X's age (Z1) is greater than the required age (Z2) for driving Vehicle Y, which directly satisfies the age requirement for driving the vehicle.\n",
    "Thought 2: In most circumstances, meeting the age requirement is a primary factor in determining eligibility to drive a vehicle, suggesting that Person X is likely eligible to drive Vehicle Y based on age.\n",
    "Thought 3: Assuming all other necessary conditions for driving (like having a valid driver's license) are also met, the age criterion being satisfied strongly indicates that Person X can legally drive Vehicle Y.\n",
    "Answer 1: Based on the Thought 1, the statement is True.\n",
    "Answer 2: Based on the Thought 2, the statement is True.\n",
    "Answer 3: Based on the Thought 3, the statement is True.\n",
    "Final Answer: The statement is True.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v2(each_rule):    \n",
    "    input = \"Right or Wrong? Please predict whether the input rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y. \\n\" + \\\n",
    "            \"Output: Right. Because Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Input: If Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y. \\n\" + \\\n",
    "            \"Output: Wrong. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_symbolic_critic_input_v2(each_rule):    \n",
    "    input = \"Right or Wrong? Please predict whether the input symbolic rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: CanDrive(Person X, Vehicle Y):- Have(Person X, Age Z1), RequireMinimumAge(Vehicle Y, Age Z2), BiggerThan(Age Z1, Age Z2); \\n\" + \\\n",
    "            \"Output: Right. Because Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Input: CanAccess(Person X, Plant Y):- BornIn(Person X, Season Z), BloomsIn(Plant Y, Season Z); \\n\" + \\\n",
    "            \"Output: Wrong. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v2_Think(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be valid and correct.\n",
    "\n",
    "Examples:\n",
    "Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y.\n",
    "Thought: If Person X's age (Z1) is indeed greater than the required age (Z2) to drive Vehicle Y, then logically, Person X meets the age requirement to drive Vehicle Y. \n",
    "Answer: Based on this thought process, the statement is Right.\n",
    "Input: If Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y.\n",
    "Thought: The fact that Person X was born in Season Z and Plant Y blooms in Season Z is a coincidence in timing and does not inherently establish a causal or enabling relationship for access. \n",
    "Answer: Based on this thought process, the statement is Wrong.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "\n",
    "def get_affordance_verbalized_critic_input_v2_Think_v2(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Note that the rule need not necessarily but just very likely to be valid and correct.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, then Person X can drive Vehicle Y.\n",
    "Thought 1: The condition states that Person X's age (Z1) is greater than the required age (Z2) for driving Vehicle Y, which directly satisfies the age requirement for driving the vehicle.\n",
    "Thought 2: In most circumstances, meeting the age requirement is a primary factor in determining eligibility to drive a vehicle, suggesting that Person X is likely eligible to drive Vehicle Y based on age.\n",
    "Thought 3: Assuming all other necessary conditions for driving (like having a valid driver's license) are also met, the age criterion being satisfied strongly indicates that Person X can legally drive Vehicle Y.\n",
    "Answer 1: Based on the Thought 1, the statement is Right.\n",
    "Answer 2: Based on the Thought 2, the statement is Right.\n",
    "Answer 3: Based on the Thought 3, the statement is Right.\n",
    "Final Answer: The statement is Right.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v3(premise, conclusion):    \n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2. \\n\" + \\\n",
    "            \"Conclusion: Person X can drive Vehicle Y. \\n\" + \\\n",
    "            \"Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Premise: Person X was born in Season Z and Plant Y blooms in the same Season Z. \\n\" + \\\n",
    "            \"Conclusion: Person X can access Plant Y. \\n\" + \\\n",
    "            \"Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \". \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_symbolic_critic_input_v3(premise, conclusion):    \n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: Have(Person X, Age Z1), RequireMinimumAge(Vehicle Y, Age Z2), BiggerThan(Age Z1, Age Z2). \\n\" + \\\n",
    "            \"Conclusion: CanDrive(Person X, Vehicle Y). \\n\" + \\\n",
    "            \"Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle. \\n\" + \\\n",
    "            \"Premise: BornIn(Person X, Season Z), BloomsIn(Plant Y, Season Z). \\n\" + \\\n",
    "            \"Conclusion: CanAccess(Person X, Plant Y). \\n\" + \\\n",
    "            \"Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \" \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v3_Think(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the premise need not necessarily but just very likely to entail the conclusion. \n",
    "\n",
    "Examples:\n",
    "Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2.\n",
    "Conclusion: Person X can drive Vehicle Y.\n",
    "Thought: If Person X's age (Z1) is indeed greater than the required age (Z2) to drive Vehicle Y, then logically, Person X meets the age requirement to drive Vehicle Y. \n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "Premise: Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y.\n",
    "Conclusion: Person X can access Plant Y.\n",
    "Thought: The fact that Person X was born in Season Z and Plant Y blooms in Season Z is a coincidence in timing and does not inherently establish a causal or enabling relationship for access. \n",
    "Answer: Based on this thought process, the answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "\n",
    "def get_affordance_verbalized_critic_input_v3_Think_v2(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Note that the premise need not necessarily but just very likely to entail the conclusion.  \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2.\n",
    "Conclusion: Person X can drive Vehicle Y.\n",
    "Thought 1: The condition states that Person X's age (Z1) is greater than the required age (Z2) for driving Vehicle Y, which directly satisfies the age requirement for driving the vehicle.\n",
    "Thought 2: In most circumstances, meeting the age requirement is a primary factor in determining eligibility to drive a vehicle, suggesting that Person X is likely eligible to drive Vehicle Y based on age.\n",
    "Thought 3: Assuming all other necessary conditions for driving (like having a valid driver's license) are also met, the age criterion being satisfied strongly indicates that Person X can legally drive Vehicle Y.\n",
    "Answer 1: Based on the Thought 1, the answer is Yes.\n",
    "Answer 2: Based on the Thought 2, the answer is Yes.\n",
    "Answer 3: Based on the Thought 3, the answer is Yes.\n",
    "Final Answer: The answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v4(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2.\n",
    "Conclusion: Person X can drive Vehicle Y. \n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle.\n",
    "Premise: Person X was born in Season Z and Plant Y blooms in the same Season Z. \n",
    "Conclusion: Person X can access Plant Y. \n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection.\n",
    "\n",
    "Premise: {premise}. \n",
    "Conclusion: {conclusion} \n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: \n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_symbolic_critic_input_v4(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Have(Person X, Age Z1), RequireMinimumAge(Vehicle Y, Age Z2), BiggerThan(Age Z1, Age Z2).\n",
    "Conclusion: CanDrive(Person X, Vehicle Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle.\n",
    "Premise: BornIn(Person X, Season Z), BloomsIn(Plant Y, Season Z).\n",
    "Conclusion: CanAccess(Person X, Plant Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection.\n",
    "\n",
    "Premise: {premise}\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v4_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2.\n",
    "Conclusion: Person X can drive Vehicle Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: If Person X's age (Z1) is indeed greater than the required age (Z2) to drive Vehicle Y, then logically, Person X meets the age requirement to drive Vehicle Y. \n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "Premise: Person X was born in Season Z and Plant Y blooms in the same Season Z, then Person X can access Plant Y.\n",
    "Conclusion: Person X can access Plant Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: The fact that Person X was born in Season Z and Plant Y blooms in Season Z is a coincidence in timing and does not inherently establish a causal or enabling relationship for access. \n",
    "Answer: Based on this thought process, the answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_affordance_verbalized_critic_input_v4_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2.\n",
    "Conclusion: Person X can drive Vehicle Y.\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting. \n",
    "Thought 1: The condition states that Person X's age (Z1) is greater than the required age (Z2) for driving Vehicle Y, which directly satisfies the age requirement for driving the vehicle.\n",
    "Thought 2: In most circumstances, meeting the age requirement is a primary factor in determining eligibility to drive a vehicle, suggesting that Person X is likely eligible to drive Vehicle Y based on age.\n",
    "Thought 3: Assuming all other necessary conditions for driving (like having a valid driver's license) are also met, the age criterion being satisfied strongly indicates that Person X can legally drive Vehicle Y.\n",
    "Answer 1: Based on the Thought 1, the answer is Yes.\n",
    "Answer 2: Based on the Thought 2, the answer is Yes.\n",
    "Answer 3: Based on the Thought 3, the answer is Yes.\n",
    "Final Answer: The answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting. \n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v5(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, can we draw the conlcusion that Person X can drive Vehicle Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle.\n",
    "Given the observations that Person X was born in Season Z and Plant Y blooms in the same Season Z, can we draw the conlcusion that Person X can access Plant Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: \n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_symbolic_critic_input_v5(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Given the observations that Have(Person X, Age Z1), RequireMinimumAge(Vehicle Y, Age Z2), BiggerThan(Age Z1, Age Z2), can we draw the conlcusion that CanDrive(Person X, Vehicle Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because the premise implies that Person X has achieved the minimum age requirement for driving vehicle.\n",
    "Given the observations that BornIn(Person X, Season Z), BloomsIn(Plant Y, Season Z), can we draw the conlcusion that CanAccess(Person X, Plant Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the season of a person's birth and the blooming season of a plant has no logical connection.\n",
    "\n",
    "Given the observations that {premise[:-1]}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: \n",
    "'''\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affordance_verbalized_critic_input_v5_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, can we draw the conlcusion that Person X can drive Vehicle Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: If Person X's age (Z1) is indeed greater than the required age (Z2) to drive Vehicle Y, then logically, Person X meets the age requirement to drive Vehicle Y. \n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "Given the observations that Person X was born in Season Z and Plant Y blooms in the same Season Z, can we draw the conlcusion that Person X can access Plant Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: The fact that Person X was born in Season Z and Plant Y blooms in Season Z is a coincidence in timing and does not inherently establish a causal or enabling relationship for access. \n",
    "Answer: Based on this thought process, the answer is No.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: \n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_affordance_verbalized_critic_input_v5_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X has an Age Z1 and Vehicle Y requires an Age above Z2 for driving, with Age Z1 being greater than Age Z2, can we draw the conlcusion that Person X can drive Vehicle Y? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting. \n",
    "Thought 1: The condition states that Person X's age (Z1) is greater than the required age (Z2) for driving Vehicle Y, which directly satisfies the age requirement for driving the vehicle.\n",
    "Thought 2: In most circumstances, meeting the age requirement is a primary factor in determining eligibility to drive a vehicle, suggesting that Person X is likely eligible to drive Vehicle Y based on age.\n",
    "Thought 3: Assuming all other necessary conditions for driving (like having a valid driver's license) are also met, the age criterion being satisfied strongly indicates that Person X can legally drive Vehicle Y.\n",
    "Answer 1: Based on the Thought 1, the answer is Yes.\n",
    "Answer 2: Based on the Thought 2, the answer is Yes.\n",
    "Answer 3: Based on the Thought 3, the answer is Yes.\n",
    "Final Answer: The answer is Yes.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input(each_rule):\n",
    "    input = \"True or False? Please predict whether the input rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\\n\" + \\\n",
    "            \"Output: False. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Input: If Person X attends School Z and School Z is located in Region Y, then Person X studies in Region Y.\\n\" + \\\n",
    "            \"Output: True. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_symbolic_critic_input(each_rule):\n",
    "    input = \"True or False? Please predict whether the input symbolic rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: LivesIn(Person X, Region Y):- BornIn(Person X, City Z), LocatedIn(City Z, Region Y); \\n\" + \\\n",
    "            \"Output: False. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Input: StudiesIn(Person X, Region Y):- Attends(Person X, School Z), LocatedIn(School Z, Region Y); \\n\" + \\\n",
    "            \"Output: True. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_Think(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be true. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\n",
    "Thought: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not mean Person X currently lives in Region Y.\n",
    "Answer: Based on this thought process, the statement is False.\n",
    "Input: If Person X attends School Z and School Z is located in Region Y, then Person X studies in Region Y.\n",
    "Thought: If Person X attends School Z, and School Z is located in Region Y, then it logically follows that Person X is studying in Region Y, as the location of the school determines where the education is taking place.\n",
    "Answer: Based on this thought process, the statement is True.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_location_verbalized_critic_input_Think_v2(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Note that the rule need not necessarily but just very likely to be true. \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\n",
    "Thought 1: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not necessarily indicate their current residency.\n",
    "Thought 2: The birthplace of a person often denotes their initial place of residence; however, it does not guarantee they continue to reside there throughout their life.\n",
    "Thought 3: While Person X's birth in City Z situates them in Region Y at the time of birth, it doesn't account for any possible relocation or movement since then.\n",
    "Answer 1: Based on the Thought 1, the statement is False.\n",
    "Answer 2: Based on the Thought 2, the statement is False.\n",
    "Answer 3: Based on the Thought 3, the statement is False.\n",
    "Final Answer: The statement is False.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v2(each_rule):\n",
    "    input = \"Right or Wrong? Please predict whether the input rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\\n\" + \\\n",
    "            \"Output: Wrong. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Input: If Person X attends School Z and School Z is located in Region Y, then Person X studies in Region Y.\\n\" + \\\n",
    "            \"Output: Right. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_symbolic_critic_input_v2(each_rule):\n",
    "    input = \"Right or Wrong? Please predict whether the input rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: LivesIn(Person X, Region Y):- BornIn(Person X, City Z), LocatedIn(City Z, Region Y); \\n\" + \\\n",
    "            \"Output: Wrong. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Input: StudiesIn(Person X, Region Y):- Attends(Person X, School Z), LocatedIn(School Z, Region Y); \\n\" + \\\n",
    "            \"Output: Right. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v2_Think(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be valid and correct. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\n",
    "Thought: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not mean Person X currently lives in Region Y.\n",
    "Answer: Based on this thought process, the statement is Wrong.\n",
    "Input: If Person X attends School Z and School Z is located in Region Y, then Person X studies in Region Y.\n",
    "Thought: If Person X attends School Z, and School Z is located in Region Y, then it logically follows that Person X is studying in Region Y, as the location of the school determines where the education is taking place.\n",
    "Answer: Based on this thought process, the statement is Right.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_location_verbalized_critic_input_v2_Think_v2(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Note that the rule need not necessarily but just very likely to be valid and correct. \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Person X is born in City Z and City Z is located in Region Y, then Person X lives in Region Y.\n",
    "Thought 1: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not necessarily indicate their current residency.\n",
    "Thought 2: The birthplace of a person often denotes their initial place of residence; however, it does not guarantee they continue to reside there throughout their life.\n",
    "Thought 3: While Person X's birth in City Z situates them in Region Y at the time of birth, it doesn't account for any possible relocation or movement since then.\n",
    "Answer 1: Based on the Thought 1, the statement is Wrong.\n",
    "Answer 2: Based on the Thought 2, the statement is Wrong.\n",
    "Answer 3: Based on the Thought 3, the statement is Wrong.\n",
    "Final Answer: The statement is Wrong.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v3(premise, conclusion):    \n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: Person X is born in City Z and City Z is located in Region Y. \\n\" + \\\n",
    "            \"Conclusion: Person X lives in Region Y. \\n\" + \\\n",
    "            \"Output: No. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Premise: Person X attends School Z and School Z is located in Region Y. \\n\" + \\\n",
    "            \"Conclusion: Person X studies in Region Y. \\n\" + \\\n",
    "            \"Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \". \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_symbolic_critic_input_v3(premise, conclusion):\n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: BornIn(Person X, City Z), LocatedIn(City Z, Region Y). \\n\" + \\\n",
    "            \"Conclusion: LivesIn(Person X, Region Y). \\n\" + \\\n",
    "            \"Output: No. Because the place of birth is not always indicative of the current place of residence. \\n\" + \\\n",
    "            \"Premise: Attends(Person X, School Z), LocatedIn(School Z, Region Y). \\n\" + \\\n",
    "            \"Conclusion: StudiesIn(Person X, Region Y). \\n\" + \\\n",
    "            \"Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \" \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v3_Think(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the premise need not necessarily but just very likely to entail the conclusion. \n",
    "\n",
    "Examples:\n",
    "Premise: Person X is born in City Z and City Z is located in Region Y.\n",
    "Conclusion: Person X lives in Region Y.\n",
    "Thought: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not mean Person X currently lives in Region Y.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Premise: Person X attends School Z and School Z is located in Region Y. \n",
    "Conclusion: Person X studies in Region Y.\n",
    "Thought: If Person X attends School Z, and School Z is located in Region Y, then it logically follows that Person X is studying in Region Y, as the location of the school determines where the education is taking place.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_location_verbalized_critic_input_v3_Think_v2(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Note that the premise need not necessarily but just very likely to entail the conclusion.  \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Premise: Person X is born in City Z and City Z is located in Region Y.\n",
    "Conclusion: Person X lives in Region Y.\n",
    "Thought 1: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not necessarily indicate their current residency.\n",
    "Thought 2: The birthplace of a person often denotes their initial place of residence; however, it does not guarantee they continue to reside there throughout their life.\n",
    "Thought 3: While Person X's birth in City Z situates them in Region Y at the time of birth, it doesn't account for any possible relocation or movement since then.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v4(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Premise: Person X is born in City Z and City Z is located in Region Y. \n",
    "Conclusion: Person X lives in Region Y.\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the place of birth is not always indicative of the current place of residence.\n",
    "Premise: Person X attends School Z and School Z is located in Region Y. \n",
    "Conclusion: Person X studies in Region Y.\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located.\n",
    "\n",
    "Premise: {premise}. \n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_symbolic_critic_input_v4(premise, conclusion):\n",
    "    input = f'''Examples:\n",
    "Premise: BornIn(Person X, City Z), LocatedIn(City Z, Region Y).\n",
    "Conclusion: LivesIn(Person X, Region Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the place of birth is not always indicative of the current place of residence.\n",
    "Premise: Attends(Person X, School Z), LocatedIn(School Z, Region Y).\n",
    "Conclusion: StudiesIn(Person X, Region Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located.\n",
    "\n",
    "Premise: {premise}\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v4_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Person X is born in City Z and City Z is located in Region Y.\n",
    "Conclusion: Person X lives in Region Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not mean Person X currently lives in Region Y.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Premise: Person X attends School Z and School Z is located in Region Y. \n",
    "Conclusion: Person X studies in Region Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: If Person X attends School Z, and School Z is located in Region Y, then it logically follows that Person X is studying in Region Y, as the location of the school determines where the education is taking place.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_location_verbalized_critic_input_v4_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Person X is born in City Z and City Z is located in Region Y.\n",
    "Conclusion: Person X lives in Region Y.\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not necessarily indicate their current residency.\n",
    "Thought 2: The birthplace of a person often denotes their initial place of residence; however, it does not guarantee they continue to reside there throughout their life.\n",
    "Thought 3: While Person X's birth in City Z situates them in Region Y at the time of birth, it doesn't account for any possible relocation or movement since then.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1:\n",
    "'''\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v5(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X is born in City Z and City Z is located in Region Y, can we draw the conlcusion that Person X lives in Region Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the place of birth is not always indicative of the current place of residence.\n",
    "Given the observations that Person X attends School Z and School Z is located in Region Y, can we draw the conlcusion that Person X studies in Region Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: \n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_symbolic_critic_input_v5(premise, conclusion):\n",
    "    input = f'''Examples:\n",
    "Given the observations that BornIn(Person X, City Z), LocatedIn(City Z, Region Y), can we draw the conlcusion that LivesIn(Person X, Region Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the place of birth is not always indicative of the current place of residence.\n",
    "Given the observations that Attends(Person X, School Z), LocatedIn(School Z, Region Y), can we draw the conlcusion that StudiesIn(Person X, Region Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because if a person attends a school, then the region in which they study is the region where the school is located.\n",
    "\n",
    "Given the observations that {premise[:-1]}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_verbalized_critic_input_v5_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X is born in City Z and City Z is located in Region Y, can we draw the conlcusion that Person X lives in Region Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not mean Person X currently lives in Region Y.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Given the observations that Person X attends School Z and School Z is located in Region Y, can we draw the conlcusion that Person X studies in Region Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: If Person X attends School Z, and School Z is located in Region Y, then it logically follows that Person X is studying in Region Y, as the location of the school determines where the education is taking place.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_location_verbalized_critic_input_v5_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Person X is born in City Z and City Z is located in Region Y, can we draw the conlcusion that Person X lives in Region Y? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1: Being born in City Z, which is located in Region Y, implies that Person X was originally from Region Y, but it does not necessarily indicate their current residency.\n",
    "Thought 2: The birthplace of a person often denotes their initial place of residence; however, it does not guarantee they continue to reside there throughout their life.\n",
    "Thought 3: While Person X's birth in City Z situates them in Region Y at the time of birth, it doesn't account for any possible relocation or movement since then.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input(each_rule):    \n",
    "    input = \"True or False? Please predict whether the input rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\\n\" + \\\n",
    "            \"Output: False. Because Show Y was available before Person X died.  \\n\" + \\\n",
    "            \"Input: If Person X lives in Region Z and Animal Y inhabits the same Region Z, then Person X can access Animal Y.\\n\" + \\\n",
    "            \"Output: True. Because person and animal exist in the same region. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_symbolic_critic_input(each_rule):    \n",
    "    input = \"True or False? Please predict whether the input rule is very likely to be true, and also explain why. Please note that the rule need not necessarily but just very likely to be true. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: CanNotAccess(Person X, Show Y):- ProducedAt(Show Y, Time Period Z1), DiedAt(Person X, Time Period Z2), EarlierThan(Time Period Z1, Time Period Z2); \\n\" + \\\n",
    "            \"Output: False. Because Show Y was available before Person X died. \\n\" + \\\n",
    "            \"Input: CanAccess(Person X, Animal Y):- LivesIn(Person X, Region Z), Inhabits(Animal Y, Region Z); \\n\" + \\\n",
    "            \"Output: True. Because person and animal exist in the same region. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_Think(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be true. \n",
    "\n",
    "Examples:\n",
    "Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\n",
    "Thought: If Show Y was produced in Time Period Z1, and Person X died in a later Time Period Z2, then logically, Person X lived during the time when Show Y was available, suggesting a possibility of access.\n",
    "Answer: Based on this thought process, the statement is False.\n",
    "Input: If Person X lives in Region Z and Animal Y inhabits the same Region Z, then Person X can access Animal Y.\n",
    "Thought: If Person X lives in Region Z and Animal Y also inhabits the same Region Z, then Person X is in the same geographical area as Animal Y, which makes access feasible.\n",
    "Answer: Based on this thought process, the statement is True.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "# Answer: Assuming all other necessary conditions are met\n",
    "\n",
    "def get_accessibility_verbalized_critic_input_Think_v2(each_rule):    \n",
    "    input = f'''True or False? Please predict whether the input rule is very likely to be true. Note that the rule need not necessarily but just very likely to be true. \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\n",
    "Thought 1: Since Show Y was produced in Time Period Z1 and Person X died in Time Period Z2, with Z1 being earlier than Z2, it suggests that Show Y existed during Person X's lifetime.\n",
    "Thought 2: The chronological order of Show Y's production and Person X's death implies that there was a period when Person X was alive and Show Y was available, allowing for potential access.\n",
    "Thought 3: Assuming no other barriers, the fact that Show Y was produced before Person X died means there was a possibility for Person X to have accessed Show Y.\n",
    "Answer 1: Based on the Thought 1, the statement is False.\n",
    "Answer 2: Based on the Thought 2, the statement is False.\n",
    "Answer 3: Based on the Thought 3, the statement is False.\n",
    "Final Answer: The statement is False.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v2(each_rule):    \n",
    "    input = \"Right or Wrong? Please predict whether the input rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\\n\" + \\\n",
    "            \"Output: Wrong. Because Show Y was available before Person X died.  \\n\" + \\\n",
    "            \"Input: If Person X lives in Region Z and Animal Y inhabits the same Region Z, then Person X can access Animal Y.\\n\" + \\\n",
    "            \"Output: Right. Because person and animal exist in the same region. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_symbolic_critic_input_v2(each_rule):    \n",
    "    input = \"Right or Wrong? Please predict whether the input rule is valid and correct, and also explain why. Please note that the rule need not necessarily but just very likely to be valid and correct. \\n\\nExamples:\\n\" + \\\n",
    "            \"Input: CanNotAccess(Person X, Show Y):- ProducedAt(Show Y, Time Period Z1), DiedAt(Person X, Time Period Z2), EarlierThan(Time Period Z1, Time Period Z2); \\n\" + \\\n",
    "            \"Output: Wrong. Because Show Y was available before Person X died. \\n\" + \\\n",
    "            \"Input: CanAccess(Person X, Animal Y):- LivesIn(Person X, Region Z), Inhabits(Animal Y, Region Z); \\n\" + \\\n",
    "            \"Output: Right. Because person and animal exist in the same region. \\n\\n\" + \\\n",
    "            \"Input: \" + each_rule + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v2_Think(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the rule need not necessarily but just very likely to be valid and correct. \n",
    "\n",
    "Examples:\n",
    "Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\n",
    "Thought: If Show Y was produced in Time Period Z1, and Person X died in a later Time Period Z2, then logically, Person X lived during the time when Show Y was available, suggesting a possibility of access.\n",
    "Answer: Based on this thought process, the statement is Wrong.\n",
    "Input: If Person X lives in Region Z and Animal Y inhabits the same Region Z, then Person X can access Animal Y.\n",
    "Thought: If Person X lives in Region Z and Animal Y also inhabits the same Region Z, then Person X is in the same geographical area as Animal Y, which makes access feasible.\n",
    "Answer: Based on this thought process, the statement is Right.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_accessibility_verbalized_critic_input_v2_Think_v2(each_rule):    \n",
    "    input = f'''Right or Wrong? Please predict whether the input rule is valid and correct. Note that the rule need not necessarily but just very likely to be valid and correct. \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Input: If Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, then Person X had no chance to access Show Y.\n",
    "Thought 1: Since Show Y was produced in Time Period Z1 and Person X died in Time Period Z2, with Z1 being earlier than Z2, it suggests that Show Y existed during Person X's lifetime.\n",
    "Thought 2: The chronological order of Show Y's production and Person X's death implies that there was a period when Person X was alive and Show Y was available, allowing for potential access.\n",
    "Thought 3: Assuming no other barriers, the fact that Show Y was produced before Person X died means there was a possibility for Person X to have accessed Show Y.\n",
    "Answer 1: Based on the Thought 1, the statement is Wrong.\n",
    "Answer 2: Based on the Thought 2, the statement is Wrong.\n",
    "Answer 3: Based on the Thought 3, the statement is Wrong.\n",
    "Final Answer: The statement is Wrong.\n",
    "\n",
    "Input: {each_rule}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v3(premise, conclusion):    \n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2. \\n\" + \\\n",
    "            \"Conclusion: Person X had no chance to access Show Y. \\n\" + \\\n",
    "            \"Output: No. Because the premise implies that Show Y was available before Person X died. \\n\" + \\\n",
    "            \"Premise: Person X lives in Region Z and Animal Y inhabits the same Region Z. \\n\" + \\\n",
    "            \"Conclusion: Person X can access Animal Y. \\n\" + \\\n",
    "            \"Output: Yes. Because the premise implies that person and animal exist in the same region. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \". \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_symbolic_critic_input_v3(premise, conclusion):    \n",
    "    input = \"Yes or No? Please predict whether the premise entails the conclusion, and also explain why. Please note that the premise need not necessarily but just very likely to entail the conclusion. \\n\\nExamples:\\n\" + \\\n",
    "            \"Premise: ProducedAt(Show Y, Time Period Z1), DiedAt(Person X, Time Period Z2), EarlierThan(Time Period Z1, Time Period Z2). \\n\" + \\\n",
    "            \"Conclusion: CanNotAccess(Person X, Show Y). \\n\" + \\\n",
    "            \"Output: No. Because the premise implies that Show Y was available before Person X died. \\n\" + \\\n",
    "            \"Premise: LivesIn(Person X, Region Z), Inhabits(Animal Y, Region Z). \\n\" + \\\n",
    "            \"Conclusion: CanAccess(Person X, Animal Y). \\n\" + \\\n",
    "            \"Output: Yes. Because the premise implies that person and animal exist in the same region. \\n\\n\"  + \\\n",
    "            \"Premise: \" + premise + \" \\n\" + \\\n",
    "            \"Conclusion: \" + conclusion + \" \\n\" + \\\n",
    "            \"Output:\\n\"\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v3_Think(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Please first briefly explain your thought process in one sentence, and then give your answer. Note that the premise need not necessarily but just very likely to entail the conclusion.\n",
    "\n",
    "Examples:\n",
    "Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2.\n",
    "Conclusion: Person X had no chance to access Show Y.\n",
    "Thought: If Show Y was produced in Time Period Z1, and Person X died in a later Time Period Z2, then logically, Person X lived during the time when Show Y was available, suggesting a possibility of access.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Premise: Person X lives in Region Z and Animal Y inhabits the same Region Z.\n",
    "Conclusion: Person X can access Animal Y.\n",
    "Thought: If Person X lives in Region Z and Animal Y also inhabits the same Region Z, then Person X is in the same geographical area as Animal Y, which makes access feasible.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_accessibility_verbalized_critic_input_v3_Think_v2(premise, conclusion):    \n",
    "    input = f'''Yes or No? Please predict whether the premise entails the conclusion. Note that the premise need not necessarily but just very likely to entail the conclusion.  \n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to give your answer. Finally, output the final answer according to majority voting. \n",
    "\n",
    "Examples:\n",
    "Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2.\n",
    "Conclusion: Person X had no chance to access Show Y.\n",
    "Thought 1: Since Show Y was produced in Time Period Z1 and Person X died in Time Period Z2, with Z1 being earlier than Z2, it suggests that Show Y existed during Person X's lifetime.\n",
    "Thought 2: The chronological order of Show Y's production and Person X's death implies that there was a period when Person X was alive and Show Y was available, allowing for potential access.\n",
    "Thought 3: Assuming no other barriers, the fact that Show Y was produced before Person X died means there was a possibility for Person X to have accessed Show Y.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v4(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2. \n",
    "Conclusion: Person X had no chance to access Show Y.\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the premise implies that Show Y was available before Person X died.\n",
    "Premise: Person X lives in Region Z and Animal Y inhabits the same Region Z. \n",
    "Conclusion: Person X can access Animal Y.\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because the premise implies that person and animal exist in the same region.\n",
    "\n",
    "Premise: {premise}. \n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_symbolic_critic_input_v4(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: ProducedAt(Show Y, Time Period Z1), DiedAt(Person X, Time Period Z2), EarlierThan(Time Period Z1, Time Period Z2).\n",
    "Conclusion: CanNotAccess(Person X, Show Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: No. Because the premise implies that Show Y was available before Person X died.\n",
    "Premise: LivesIn(Person X, Region Z), Inhabits(Animal Y, Region Z).\n",
    "Conclusion: CanAccess(Person X, Animal Y).\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output: Yes. Because the premise implies that person and animal exist in the same region.\n",
    "\n",
    "Premise: {premise}\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please answer Yes or No, and also explain why. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v4_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2.\n",
    "Conclusion: Person X had no chance to access Show Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: If Show Y was produced in Time Period Z1, and Person X died in a later Time Period Z2, then logically, Person X lived during the time when Show Y was available, suggesting a possibility of access.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Premise: Person X lives in Region Z and Animal Y inhabits the same Region Z.\n",
    "Conclusion: Person X can access Animal Y.\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought: If Person X lives in Region Z and Animal Y also inhabits the same Region Z, then Person X is in the same geographical area as Animal Y, which makes access feasible.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Thought:\n",
    "    '''\n",
    "    return input\n",
    "\n",
    "def get_accessibility_verbalized_critic_input_v4_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Premise: Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2.\n",
    "Conclusion: Person X had no chance to access Show Y.\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1: Since Show Y was produced in Time Period Z1 and Person X died in Time Period Z2, with Z1 being earlier than Z2, it suggests that Show Y existed during Person X's lifetime.\n",
    "Thought 2: The chronological order of Show Y's production and Person X's death implies that there was a period when Person X was alive and Show Y was available, allowing for potential access.\n",
    "Thought 3: Assuming no other barriers, the fact that Show Y was produced before Person X died means there was a possibility for Person X to have accessed Show Y.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Premise: {premise}.\n",
    "Conclusion: {conclusion}\n",
    "Is this conclusion logically supported by the given premise? Note that the premise need not necessarily but just very likely to support the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1:\n",
    "'''\n",
    "\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v5(premise, conclusion): \n",
    "    input = f'''Examples:\n",
    "Given the observations that Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, can we draw the conlcusion that Person X had no chance to access Show Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the premise implies that Show Y was available before Person X died.\n",
    "Given the observations that Person X lives in Region Z and Animal Y inhabits the same Region Z, can we draw the conlcusion that Person X can access Animal Y?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because the premise implies that person and animal exist in the same region.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: \n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_symbolic_critic_input_v5(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that ProducedAt(Show Y, Time Period Z1), DiedAt(Person X, Time Period Z2), EarlierThan(Time Period Z1, Time Period Z2), can we draw the conlcusion that CanNotAccess(Person X, Show Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: No. Because the premise implies that Show Y was available before Person X died.\n",
    "Given the observations that LivesIn(Person X, Region Z), Inhabits(Animal Y, Region Z), can we draw the conlcusion that CanAccess(Person X, Animal Y)?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output: Yes. Because the premise implies that person and animal exist in the same region.\n",
    "\n",
    "Given the observations that {premise[:-1]}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please answer Yes or No, and also explain why. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Output:\n",
    "'''\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessibility_verbalized_critic_input_v5_Think(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, can we draw the conlcusion that Person X had no chance to access Show Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: If Show Y was produced in Time Period Z1, and Person X died in a later Time Period Z2, then logically, Person X lived during the time when Show Y was available, suggesting a possibility of access.\n",
    "Answer: Based on this thought process, the answer is No.\n",
    "Given the observations that Person X lives in Region Z and Animal Y inhabits the same Region Z, can we draw the conlcusion that Person X can access Animal Y?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought: If Person X lives in Region Z and Animal Y also inhabits the same Region Z, then Person X is in the same geographical area as Animal Y, which makes access feasible.\n",
    "Answer: Based on this thought process, the answer is Yes.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}?\n",
    "Please first briefly explain your thought process in one sentence, and then answer Yes or No. Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Thought:\n",
    "'''\n",
    "    return input\n",
    "\n",
    "def get_accessibility_verbalized_critic_input_v5_Think_v2(premise, conclusion):    \n",
    "    input = f'''Examples:\n",
    "Given the observations that Show Y was produced at Time Period Z1, Person X died at a Time Period Z2, and Time Period Z1 is earlier than Time Period Z2, can we draw the conlcusion that Person X had no chance to access Show Y? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1: Since Show Y was produced in Time Period Z1 and Person X died in Time Period Z2, with Z1 being earlier than Z2, it suggests that Show Y existed during Person X's lifetime.\n",
    "Thought 2: The chronological order of Show Y's production and Person X's death implies that there was a period when Person X was alive and Show Y was available, allowing for potential access.\n",
    "Thought 3: Assuming no other barriers, the fact that Show Y was produced before Person X died means there was a possibility for Person X to have accessed Show Y.\n",
    "Answer 1: Based on the Thought 1, the answer is No.\n",
    "Answer 2: Based on the Thought 2, the answer is No.\n",
    "Answer 3: Based on the Thought 3, the answer is No.\n",
    "Final Answer: The answer is No.\n",
    "\n",
    "Given the observations that {premise}, can we draw the conlcusion that {conclusion[:-1]}? Note that the observations need not necessarily but just very likely to draw the conclusion.\n",
    "Please first generate three different sentences to respectively explain your three thought processes briefly, and then based on the corresponding thought to answer Yes or No. Finally, output the final answer according to majority voting.\n",
    "Thought 1:\n",
    "'''\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_human_result(result_file):\n",
    "    all_data = []\n",
    "    with open(result_file) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            all_data.append(row)\n",
    "\n",
    "    annotation_dict_correct = {}\n",
    "    for i in range(1, len(all_data)):\n",
    "        entry_id = all_data[i][27]\n",
    "        if entry_id not in annotation_dict_correct:\n",
    "            annotation_dict_correct[entry_id] = [all_data[i][32]]\n",
    "        else:\n",
    "            annotation_dict_correct[entry_id].append(all_data[i][32]) \n",
    "    print(len(annotation_dict_correct))\n",
    "    return annotation_dict_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def probing_both_valid_invalid_rules(rules, model='GPT-4', type=\"\", version=\"\", think_v=\"\", max_tokens=400):\n",
    "\n",
    "    if os.path.exists(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json'):\n",
    "        with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'r') as r_f:\n",
    "            label_list = json.load(r_f)\n",
    "    else:\n",
    "        label_list = {}\n",
    "        \n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "    print(len(selected_index))\n",
    "\n",
    "    acc_num = 0\n",
    "    unnecessary_num = 0\n",
    "    for i in tqdm(selected_index):\n",
    "        if True:\n",
    "            each_rule = rules[i]['v_rule'].strip()\n",
    "\n",
    "            # modify pos rules into neg rules \n",
    "            assert each_rule[:3] == \"If \" and \", then \" in each_rule\n",
    "            premise, conclusion = each_rule.split(\", then \")\n",
    "            original_conclusion = conclusion\n",
    "\n",
    "            if \"cannot\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"cannot\", \"can\")\n",
    "            elif \"can\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"can\", \"cannot\")\n",
    "            elif \" not\" in conclusion or \"not \" in conclusion:\n",
    "                conclusion = conclusion.replace(\" not\", \"\").replace(\"not \", \"\")\n",
    "            else:\n",
    "                conc_tokens = conclusion.split()\n",
    "                if \"X\" in conc_tokens and \"Y\" in conc_tokens:\n",
    "                    person_index = min(conc_tokens.index(\"X\"), conc_tokens.index(\"Y\"))\n",
    "                elif \"X\" in conc_tokens:\n",
    "                    person_index = conc_tokens.index(\"X\")\n",
    "                elif \"Y\" in conc_tokens:\n",
    "                    person_index = conc_tokens.index(\"Y\")\n",
    "                else:\n",
    "                    print(conc_tokens)\n",
    "                    person_index = conc_tokens.index(\"Y.\")\n",
    "                conc_tokens = conc_tokens[:person_index+2] + ['not'] + conc_tokens[person_index+2:]\n",
    "                conclusion = \" \".join(conc_tokens)\n",
    "            edit_rule = premise + \", then \" + conclusion\n",
    "\n",
    "            if version == \"\" or version == \"_v2\":\n",
    "                if rules[i]['domain']==\"affordance\":\n",
    "                    probing_input = eval(f\"get_affordance_verbalized_critic_input{version}{think_v}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_affordance_verbalized_critic_input{version}{think_v}\")(edit_rule)\n",
    "                elif rules[i]['domain'] == \"accessibility\":\n",
    "                    probing_input = eval(f\"get_accessibility_verbalized_critic_input{version}{think_v}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_accessibility_verbalized_critic_input{version}{think_v}\")(edit_rule)\n",
    "                else:\n",
    "                    probing_input = eval(f\"get_location_verbalized_critic_input{version}{think_v}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_location_verbalized_critic_input{version}{think_v}\")(edit_rule)\n",
    "            else:\n",
    "                if rules[i]['domain']==\"affordance\":\n",
    "                    probing_input = eval(f\"get_affordance_verbalized_critic_input{version}{think_v}\")(premise[3:], original_conclusion)\n",
    "                    valid_probing_input = eval(f\"get_affordance_verbalized_critic_input{version}{think_v}\")(premise[3:], conclusion)\n",
    "                elif rules[i]['domain'] == \"accessibility\":\n",
    "                    probing_input = eval(f\"get_accessibility_verbalized_critic_input{version}{think_v}\")(premise[3:], original_conclusion)\n",
    "                    valid_probing_input = eval(f\"get_accessibility_verbalized_critic_input{version}{think_v}\")(premise[3:], conclusion)\n",
    "                else:\n",
    "                    probing_input = eval(f\"get_location_verbalized_critic_input{version}{think_v}\")(premise[3:], original_conclusion)\n",
    "                    valid_probing_input = eval(f\"get_location_verbalized_critic_input{version}{think_v}\")(premise[3:], conclusion)\n",
    "\n",
    "            if model == 'GPT-4' or model == 'GPT-4-preview':\n",
    "                response = get_GPT4_response(probing_input, max_tokens=max_tokens, temp=0)\n",
    "                valid_response = get_GPT4_response(valid_probing_input, max_tokens=max_tokens, temp=0)\n",
    "            elif model == 'GPT-3.5':\n",
    "                response = get_GPT4_response(probing_input, max_tokens=max_tokens, temp=0, model=\"gpt-3.5-turbo-0613\")\n",
    "                valid_response = get_GPT4_response(valid_probing_input, max_tokens=max_tokens, temp=0, model=\"gpt-3.5-turbo-0613\")\n",
    "            else:\n",
    "                response = get_davinci3_response(probing_input, max_tokens=max_tokens, temp=0)\n",
    "                valid_response = get_davinci3_response(valid_probing_input, max_tokens=max_tokens, temp=0)\n",
    "            \n",
    "            # print(response)\n",
    "            assert \"Final Answer:\" in response and \"Final Answer:\" in valid_response, \"Error in response\"\n",
    "            response = response.split(\"Final Answer:\")[-1].strip()\n",
    "            valid_response = valid_response.split(\"Final Answer:\")[-1].strip()\n",
    "\n",
    "            if version == \"\":\n",
    "                if \"True\" in response and \"False\" not in response and \"False\" in valid_response and \"True\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 0\n",
    "            elif version == \"_v2\":\n",
    "                if \"Right\" in response and \"Wrong\" not in response and \"Wrong\" in valid_response and \"Right\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 0\n",
    "            elif version == \"_v3\" or version == \"_v4\" or version == \"_v5\":\n",
    "                if \"Yes\" in response and \"No\" not in response and \"No\" in valid_response and \"Yes\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"{think_v}{rules[i]['s_rule'].strip()}\"] = 0\n",
    "\n",
    "    print(acc_num, unnecessary_num)\n",
    "    # with open(f'ScriptData/Primitive/Analysis_data_v2/annotations{version}/{model}.json', 'w') as w_f:\n",
    "    with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'w') as w_f:\n",
    "        json.dump(label_list, w_f, indent=1)\n",
    "    print(model, type, acc_num, acc_num/len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def probing_both_valid_invalid_symbolic_rules(rules, model='GPT-4', type=\"\", version=\"\", rule_type=\"symbolic\"):\n",
    "    if os.path.exists(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json'):\n",
    "        with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'r') as r_f:\n",
    "            label_list = json.load(r_f)\n",
    "    else:\n",
    "        label_list = {}\n",
    "        \n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "    print(len(selected_index))\n",
    "\n",
    "    acc_num = 0\n",
    "    for i in tqdm(selected_index):\n",
    "        if \"Sym \" + rules[i]['s_rule'].strip() in label_list:\n",
    "            acc_num += label_list[\"Sym \" + rules[i]['s_rule'].strip()]\n",
    "        else:\n",
    "            each_rule = rules[i]['s_rule'].strip()\n",
    "            # modify pos rules into neg rules \n",
    "            assert each_rule[-1] == \";\"\n",
    "            conclusion, premise = each_rule[:-1].split(\":- \")\n",
    "            original_conclusion = conclusion\n",
    "\n",
    "            if \"CanNot\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"CanNot\", \"Can\")\n",
    "            elif \"Cannot\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"Cannot\", \"Can\")\n",
    "            elif \"Can\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"Can\", \"CanNot\")\n",
    "            elif \"Not\" in conclusion or \"not\" in conclusion:\n",
    "                conclusion = conclusion.replace(\"Not\", \"\").replace(\"not \", \"\")\n",
    "            else:\n",
    "                conclusion = \"Not\" + conclusion\n",
    "            edit_rule = conclusion + \":- \" + premise + \";\"\n",
    "\n",
    "            if version == \"\" or version == \"_v2\":\n",
    "                if rules[i]['domain']==\"affordance\":\n",
    "                    probing_input = eval(f\"get_affordance_{rule_type}_critic_input{version}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_affordance_{rule_type}_critic_input{version}\")(edit_rule)\n",
    "                elif rules[i]['domain'] == \"accessibility\":\n",
    "                    probing_input = eval(f\"get_accessibility_{rule_type}_critic_input{version}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_accessibility_{rule_type}_critic_input{version}\")(edit_rule)\n",
    "                else:\n",
    "                    probing_input = eval(f\"get_location_{rule_type}_critic_input{version}\")(each_rule)\n",
    "                    valid_probing_input = eval(f\"get_location_{rule_type}_critic_input{version}\")(edit_rule)\n",
    "            else:\n",
    "                if rules[i]['domain']==\"affordance\":\n",
    "                    probing_input = eval(f\"get_affordance_{rule_type}_critic_input{version}\")(premise+\".\", original_conclusion+\".\")\n",
    "                    valid_probing_input = eval(f\"get_affordance_{rule_type}_critic_input{version}\")(premise+\".\", conclusion+\".\")\n",
    "                elif rules[i]['domain'] == \"accessibility\":\n",
    "                    probing_input = eval(f\"get_accessibility_{rule_type}_critic_input{version}\")(premise+\".\", original_conclusion+\".\")\n",
    "                    valid_probing_input = eval(f\"get_accessibility_{rule_type}_critic_input{version}\")(premise+\".\", conclusion+\".\")\n",
    "                else:\n",
    "                    probing_input = eval(f\"get_location_{rule_type}_critic_input{version}\")(premise+\".\", original_conclusion+\".\")\n",
    "                    valid_probing_input = eval(f\"get_location_{rule_type}_critic_input{version}\")(premise+\".\", conclusion+\".\")\n",
    "\n",
    "            if model == 'GPT-4':\n",
    "                response = get_GPT4_response(probing_input, max_tokens=50, temp=0)\n",
    "                valid_response = get_GPT4_response(valid_probing_input, max_tokens=50, temp=0)\n",
    "            elif model == 'GPT-3.5':\n",
    "                response = get_GPT4_response(probing_input, max_tokens=50, temp=0, model=\"gpt-3.5-turbo-0613\")\n",
    "                valid_response = get_GPT4_response(valid_probing_input, max_tokens=50, temp=0, model=\"gpt-3.5-turbo-0613\")\n",
    "            else:\n",
    "                response = get_davinci3_response(probing_input, max_tokens=50, temp=0)\n",
    "                valid_response = get_davinci3_response(valid_probing_input, max_tokens=50, temp=0)\n",
    "            # print(each_rule)\n",
    "            # print(response[:150])\n",
    "            # print(edit_rule)\n",
    "            # print(valid_response[:150])\n",
    "            # print(\"*\"*50)\n",
    "            if version == \"\":\n",
    "                if \"True\" in response and \"False\" not in response and \"False\" in valid_response and \"True\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 0\n",
    "            elif version == \"_v2\":\n",
    "                if \"Right\" in response and \"Wrong\" not in response and \"Wrong\" in valid_response and \"Right\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 0\n",
    "            elif version == \"_v3\" or version == \"_v4\" or version == \"_v5\":\n",
    "                if \"Yes\" in response and \"No\" not in response and \"No\" in valid_response and \"Yes\" not in valid_response:\n",
    "                    acc_num += 1\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 1\n",
    "                else:\n",
    "                    label_list[f\"Sym {rules[i]['s_rule'].strip()}\"] = 0\n",
    "            \n",
    "    with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'w') as w_f:\n",
    "        json.dump(label_list, w_f, indent=1)\n",
    "    print(model, type, acc_num, acc_num/len(selected_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "def probing_valid_rules_human(rules, type=\"\"):\n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "\n",
    "        \n",
    "    acc_num = 0\n",
    "    for i in tqdm(selected_index):\n",
    "        if rules[i]['label']:\n",
    "            if rules[i]['original_turk'] == \"2\" and rules[i]['flipped_turk'] == \"1\":\n",
    "                acc_num += 1\n",
    "    print(\"human\", type, acc_num/len(selected_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probing experiment with high-quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def compute_overlap(candidate_list, new_sentence):\n",
    "    new_sentence_tokens = set(new_sentence.lower().split())\n",
    "    for each in candidate_list:\n",
    "        if len(set(each) & new_sentence_tokens) / len(new_sentence_tokens) > 0.8 or len(set(each) & new_sentence_tokens) / len(set(each)) > 0.8:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# seed = 42\n",
    "import json\n",
    "def analysis_length(model='GPT-4', valid=True, positive=False, version=\"\"):\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    length_1_list = []\n",
    "    length_2_list = []\n",
    "    length_3_list = []\n",
    "    length_4_list = []\n",
    "    length_1_list_tokens = []\n",
    "    length_2_list_tokens = []\n",
    "    length_3_list_tokens = []\n",
    "    length_4_list_tokens = []\n",
    "    for _ in range(len(all_data)):\n",
    "        if all_data[_]['length'] == 1:\n",
    "            if compute_overlap(length_1_list_tokens, all_data[_]['v_rule']):\n",
    "                length_1_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_1_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 2:\n",
    "            if compute_overlap(length_2_list_tokens, all_data[_]['v_rule']):\n",
    "                length_2_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_2_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 3:\n",
    "            if compute_overlap(length_3_list_tokens, all_data[_]['v_rule']):\n",
    "                length_3_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_3_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 4:\n",
    "            if compute_overlap(length_4_list_tokens, all_data[_]['v_rule']):\n",
    "                length_4_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_4_list.append(all_data[_])\n",
    "    print(len(length_1_list), len(length_2_list), len(length_3_list), len(length_4_list))\n",
    "\n",
    "    if model == \"human\":\n",
    "        probing_valid_rules_human(length_4_list, type=\"Length 4\")\n",
    "        probing_valid_rules_human(length_3_list, type=\"Length 3\")\n",
    "        probing_valid_rules_human(length_2_list, type=\"Length 2\")\n",
    "        probing_valid_rules_human(length_1_list, type=\"Length 1\")\n",
    "    else:\n",
    "        # probing_both_valid_invalid_rules(length_4_list, model=model, type=\"Length 4\", version=version)\n",
    "        # probing_both_valid_invalid_rules(length_3_list, model=model, type=\"Length 3\", version=version)\n",
    "        # probing_both_valid_invalid_rules(length_2_list, model=model, type=\"Length 2\", version=version)\n",
    "        # probing_both_valid_invalid_rules(length_1_list, model=model, type=\"Length 1\", version=version)\n",
    "\n",
    "        probing_both_valid_invalid_symbolic_rules(length_4_list, model=model, type=\"Length 4\", version=version)\n",
    "        probing_both_valid_invalid_symbolic_rules(length_3_list, model=model, type=\"Length 3\", version=version)\n",
    "        probing_both_valid_invalid_symbolic_rules(length_2_list, model=model, type=\"Length 2\", version=version)\n",
    "        probing_both_valid_invalid_symbolic_rules(length_1_list, model=model, type=\"Length 1\", version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 181747.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Length 4 0.896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 294130.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Length 3 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 251256.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Length 2 0.9866666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 60096.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Length 1 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_length(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 323067.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Length 4 22 0.1896551724137931\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 181624.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Length 3 29 0.19333333333333333\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 287806.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Length 2 49 0.32666666666666666\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 139654.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 Length 1 98 0.6533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 152233.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 4 2 0.017241379310344827\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 216797.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 3 7 0.04666666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 209785.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 2 5 0.03333333333333333\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 182097.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 1 47 0.31333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 395560.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Length 4 69 0.5948275862068966\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 134663.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Length 3 106 0.7066666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 266474.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Length 2 143 0.9533333333333334\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 353850.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Length 1 128 0.8533333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_length(\"GPT-3.5\")\n",
    "analysis_length(\"GPT-3.5-Instruct\")\n",
    "analysis_length(\"GPT-4\")\n",
    "\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v2\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v3\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v4\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v5\")\n",
    "\n",
    "# analysis_length(\"GPT-4\", version=\"_v2\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v3\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v4\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v5\")\n",
    "\n",
    "# analysis_length(\"GPT-3.5-Instruct\", version=\"_v2\")\n",
    "# analysis_length(\"GPT-3.5-Instruct\", version=\"_v3\")\n",
    "# analysis_length(\"GPT-3.5-Instruct\", version=\"_v4\")\n",
    "# analysis_length(\"GPT-3.5-Instruct\", version=\"_v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 136822.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 4 0 0.0\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 56771.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 3 0 0.0\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 175005.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 2 1 0.006666666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 251256.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 1 5 0.03333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 192080.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 4 10 0.08620689655172414\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 136622.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 3 13 0.08666666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 151528.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 2 50 0.3333333333333333\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 172984.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 1 116 0.7733333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 143015.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 4 1 0.008620689655172414\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 115736.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 3 4 0.02666666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 457560.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 2 27 0.18\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 462607.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 1 98 0.6533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [00:00<00:00, 208994.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 4 24 0.20689655172413793\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 187524.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 3 44 0.29333333333333333\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 207775.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 2 73 0.4866666666666667\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 230794.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5-Instruct Length 1 108 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analysis_length(\"GPT-3.5\", version=\"_v2\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v3\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v4\")\n",
    "# analysis_length(\"GPT-3.5\", version=\"_v5\")\n",
    "\n",
    "# analysis_length(\"GPT-4\", version=\"_v2\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v3\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v4\")\n",
    "# analysis_length(\"GPT-4\", version=\"_v5\")\n",
    "\n",
    "analysis_length(\"GPT-3.5-Instruct\", version=\"_v2\")\n",
    "analysis_length(\"GPT-3.5-Instruct\", version=\"_v3\")\n",
    "analysis_length(\"GPT-3.5-Instruct\", version=\"_v4\")\n",
    "analysis_length(\"GPT-3.5-Instruct\", version=\"_v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_accuracy(rules, model='GPT-4', version=\"\"):\n",
    "    assert os.path.exists(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json')\n",
    "    with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'r') as r_f:\n",
    "        label_list = json.load(r_f)\n",
    "\n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "    # print(len(selected_index))\n",
    "\n",
    "    acc_num = 0\n",
    "    for i in selected_index:\n",
    "        assert rules[i]['s_rule'].strip() in label_list\n",
    "        acc_num += label_list[rules[i]['s_rule'].strip()]\n",
    "        # assert \"Sym \" + rules[i]['s_rule'].strip() in label_list\n",
    "        # acc_num += label_list[\"Sym \" + rules[i]['s_rule'].strip()]\n",
    "    return acc_num/len(selected_index)\n",
    "    \n",
    "from tqdm import tqdm\n",
    "def compute_overlap(candidate_list, new_sentence):\n",
    "    new_sentence_tokens = set(new_sentence.lower().split())\n",
    "    for each in candidate_list:\n",
    "        if len(set(each) & new_sentence_tokens) / len(new_sentence_tokens) > 0.8 or len(set(each) & new_sentence_tokens) / len(set(each)) > 0.8:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def analysis_length_alltogether(model='GPT-4', positive=False):\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    version = [\"\", \"_v2\", \"_v3\", \"_v4\", \"_v5\"]\n",
    "\n",
    "    length_1_list = []\n",
    "    length_2_list = []\n",
    "    length_3_list = []\n",
    "    length_4_list = []\n",
    "    length_5_list = []\n",
    "    length_1_list_tokens = []\n",
    "    length_2_list_tokens = []\n",
    "    length_3_list_tokens = []\n",
    "    length_4_list_tokens = []\n",
    "    for _ in range(len(all_data)):\n",
    "        if all_data[_]['length'] == 1:\n",
    "            if compute_overlap(length_1_list_tokens, all_data[_]['v_rule']):\n",
    "                length_1_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_1_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 2:\n",
    "            if compute_overlap(length_2_list_tokens, all_data[_]['v_rule']):\n",
    "                length_2_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_2_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 3:\n",
    "            if compute_overlap(length_3_list_tokens, all_data[_]['v_rule']):\n",
    "                length_3_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_3_list.append(all_data[_])\n",
    "        elif all_data[_]['length'] == 4:\n",
    "            if compute_overlap(length_4_list_tokens, all_data[_]['v_rule']):\n",
    "                length_4_list_tokens.append(all_data[_]['v_rule'].lower().split())\n",
    "                length_4_list.append(all_data[_])\n",
    "        else:\n",
    "            length_5_list.append(all_data[_])\n",
    "    print(len(length_1_list), len(length_2_list), len(length_3_list), len(length_4_list), len(length_5_list))\n",
    "    \n",
    "    if model == \"human\":\n",
    "        probing_valid_rules_human(length_1_list, type=\"Length 1\")\n",
    "        probing_valid_rules_human(length_2_list, type=\"Length 2\")\n",
    "        probing_valid_rules_human(length_3_list, type=\"Length 3\")\n",
    "        probing_valid_rules_human(length_4_list, type=\"Length 4\")\n",
    "        probing_valid_rules_human(length_5_list, type=\"Length 5\")\n",
    "    else:\n",
    "        all_acc_list = []\n",
    "        all_deviation_list = []\n",
    "        for type in [\"Length 1\", \"Length 2\", \"Length 3\", \"Length 4\", \"Length 5\"]: \n",
    "            if type == \"Length 1\": \n",
    "                rules = length_1_list\n",
    "            elif type == \"Length 2\":\n",
    "                rules = length_2_list\n",
    "            elif type == \"Length 3\":\n",
    "                rules = length_3_list\n",
    "            elif type == \"Length 4\":\n",
    "                rules = length_4_list\n",
    "            elif type == \"Length 5\":\n",
    "                rules = length_5_list\n",
    "            all_acc = []\n",
    "            for each_v in version:\n",
    "                cur_acc = get_accuracy(rules, model=model, version=each_v)\n",
    "                all_acc.append(cur_acc)\n",
    "            avg_acc = sum(all_acc)/len(all_acc)\n",
    "            deviation = np.std(all_acc)\n",
    "            \n",
    "            all_acc_list.append(round(avg_acc, 3))\n",
    "            all_deviation_list.append(round(deviation, 3))\n",
    "        print(all_acc_list)\n",
    "        print(all_deviation_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116 107\n",
      "[0.904, 0.885, 0.823, 0.716, 0.665]\n",
      "[0.037, 0.027, 0.029, 0.034, 0.049]\n"
     ]
    }
   ],
   "source": [
    "analysis_length_alltogether(model='GPT-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 432 195 116 107\n",
      "[0.913, 0.917, 0.715, 0.693, 0.568]\n",
      "[0.033, 0.037, 0.051, 0.06, 0.051]\n",
      "254 432 195 116 107\n",
      "[0.811, 0.732, 0.483, 0.448, 0.321]\n",
      "[0.092, 0.177, 0.161, 0.176, 0.207]\n"
     ]
    }
   ],
   "source": [
    "analysis_length_alltogether(model='GPT-3.5')\n",
    "analysis_length_alltogether(model='GPT-3.5-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "import json\n",
    "def analysis_depth(model='GPT-4', valid=True, positive=False, version=\"\"):\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    depth_0_list = []\n",
    "    depth_1_list = []\n",
    "    depth_2_list = []\n",
    "    depth_3_list = []\n",
    "    for _ in range(len(all_data)):\n",
    "        # if all_data[_]['positive'] == positive:\n",
    "        if all_data[_]['depth'] == 0:\n",
    "            depth_0_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 1:\n",
    "            depth_1_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 2:\n",
    "            depth_2_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 3:\n",
    "            depth_3_list.append(all_data[_])\n",
    "    print(len(depth_0_list), len(depth_1_list), len(depth_2_list), len(depth_3_list))\n",
    "    \n",
    "    if model == \"human\":\n",
    "        probing_valid_rules_human(depth_3_list, type=\"Depth 3\")\n",
    "        probing_valid_rules_human(depth_2_list, type=\"Depth 2\")\n",
    "        probing_valid_rules_human(depth_1_list, type=\"Depth 1\")\n",
    "        probing_valid_rules_human(depth_0_list, type=\"Depth 0\")\n",
    "    else:\n",
    "        probing_both_valid_invalid_rules(depth_0_list, model=model, type=\"Depth 0\", version=version)\n",
    "        probing_both_valid_invalid_rules(depth_1_list, model=model, type=\"Depth 1\", version=version)\n",
    "        probing_both_valid_invalid_rules(depth_2_list, model=model, type=\"Depth 2\", version=version)\n",
    "        probing_both_valid_invalid_rules(depth_3_list, model=model, type=\"Depth 3\", version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 149 114 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 58956.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Depth 3 0.7792207792207793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 527760.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Depth 2 0.8421052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:00<00:00, 289195.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Depth 1 0.912751677852349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 94225.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human Depth 0 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_depth(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_depth(\"GPT-3.5\")\n",
    "# analysis_depth(\"GPT-4\")\n",
    "# analysis_depth(\"GPT-3.5-Instruct\")\n",
    "\n",
    "analysis_depth(\"GPT-4\", version=\"_v2\")\n",
    "analysis_depth(\"GPT-4\", version=\"_v3\")\n",
    "analysis_depth(\"GPT-4\", version=\"_v4\")\n",
    "analysis_depth(\"GPT-4\", version=\"_v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_accuracy(rules, model='GPT-4', version=\"\"):\n",
    "    assert os.path.exists(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json')\n",
    "    with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'r') as r_f:\n",
    "        label_list = json.load(r_f)\n",
    "\n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "    # print(len(selected_index))\n",
    "\n",
    "    acc_num = 0\n",
    "    for i in selected_index:\n",
    "        assert rules[i]['s_rule'].strip() in label_list\n",
    "        acc_num += label_list[rules[i]['s_rule'].strip()]\n",
    "    return acc_num/len(selected_index)\n",
    "    \n",
    "\n",
    "def analysis_depth_alltogether(model='GPT-4', positive=False):\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    version = [\"\", \"_v2\", \"_v3\", \"_v4\", \"_v5\"]\n",
    "\n",
    "    depth_0_list = []\n",
    "    depth_1_list = []\n",
    "    depth_2_list = []\n",
    "    depth_3_list = []\n",
    "    for _ in range(len(all_data)):\n",
    "        if all_data[_]['depth'] == 0:\n",
    "            depth_0_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 1:\n",
    "            depth_1_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 2:\n",
    "            depth_2_list.append(all_data[_])\n",
    "        elif all_data[_]['depth'] == 3:\n",
    "            depth_3_list.append(all_data[_])\n",
    "    print(len(depth_0_list), len(depth_1_list), len(depth_2_list), len(depth_3_list))\n",
    "    \n",
    "    if model == \"human\":\n",
    "        probing_valid_rules_human(depth_3_list, type=\"Depth 3\")\n",
    "        probing_valid_rules_human(depth_2_list, type=\"Depth 2\")\n",
    "        probing_valid_rules_human(depth_1_list, type=\"Depth 1\")\n",
    "        probing_valid_rules_human(depth_0_list, type=\"Depth 0\")\n",
    "    else:\n",
    "        all_acc_list = []\n",
    "        all_deviation_list = []\n",
    "        for type in [\"Depth 0\", \"Depth 1\", \"Depth 2\", \"Depth 3\"]: #\n",
    "            if type == \"Depth 0\":\n",
    "                rules = depth_0_list\n",
    "            elif type == \"Depth 1\":\n",
    "                rules = depth_1_list\n",
    "            elif type == \"Depth 2\":\n",
    "                rules = depth_2_list\n",
    "            else:\n",
    "                rules = depth_3_list\n",
    "            all_acc = []\n",
    "            for each_v in version:\n",
    "                cur_acc = get_accuracy(rules, model=model, version=each_v)\n",
    "                all_acc.append(cur_acc)\n",
    "            avg_acc = sum(all_acc)/len(all_acc)\n",
    "            deviation = np.std(all_acc)\n",
    "            \n",
    "            all_acc_list.append(round(avg_acc, 3))\n",
    "            all_deviation_list.append(round(deviation, 3))\n",
    "        print(all_acc_list)\n",
    "        print(all_deviation_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 149 114 77\n",
      "[0.915, 0.777, 0.681, 0.665]\n",
      "[0.02, 0.04, 0.039, 0.052]\n",
      "764 149 114 77\n",
      "[0.859, 0.737, 0.686, 0.629]\n",
      "[0.026, 0.044, 0.055, 0.077]\n",
      "764 149 114 77\n",
      "[0.672, 0.514, 0.463, 0.348]\n",
      "[0.166, 0.16, 0.186, 0.234]\n"
     ]
    }
   ],
   "source": [
    "analysis_depth_alltogether(model='GPT-4')\n",
    "analysis_depth_alltogether(\"GPT-3.5\")\n",
    "analysis_depth_alltogether(\"GPT-3.5-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def analysis_detailed_structure(model='GPT-4', positive=True, version = \"\", think_v=\"_Think_v2\"): #_Think_v2\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    structure_d_list = []\n",
    "    structure_t_0_list = []\n",
    "    structure_t_more_list = []\n",
    "    structure_t_1_list = []\n",
    "    structure_t_2_list = []\n",
    "    structure_t_3_list = []\n",
    "    structure_joint_list = []\n",
    "    structure_joint_1_list = []\n",
    "    structure_joint_2_list = []\n",
    "    structure_joint_3_list = []\n",
    "    for _ in range(len(all_data)):\n",
    "        if all_data[_]['positive'] == positive: # and all_data[_]['length'] > 1: #or all_data[_]['positive'] != positive:\n",
    "            structure_t_3_list.append(all_data[_])\n",
    "\n",
    "            if all_data[_]['structure'] == \"disjunctive\":\n",
    "                structure_d_list.append(all_data[_])\n",
    "            elif all_data[_]['structure'] == \"transitive\" and all_data[_]['length'] > 1:\n",
    "                structure_t_more_list.append(all_data[_])\n",
    "                if all_data[_]['depth'] == 0:\n",
    "                    structure_t_0_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] >= 1 and all_data[_]['depth'] <= 3:\n",
    "                    if all_data[_]['depth'] == 1:\n",
    "                        structure_t_1_list.append(all_data[_])\n",
    "                    elif all_data[_]['depth'] == 2:\n",
    "                        structure_t_2_list.append(all_data[_])\n",
    "                    # else:\n",
    "                    #     structure_t_3_list.append(all_data[_])\n",
    "            elif all_data[_]['structure'] == \"transitive-disjunctive\":\n",
    "                structure_joint_list.append(all_data[_])\n",
    "                if all_data[_]['depth'] == 1:\n",
    "                    structure_joint_1_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] == 2:\n",
    "                    structure_joint_2_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] == 3:\n",
    "                    structure_joint_3_list.append(all_data[_])\n",
    "    print(len(structure_d_list))\n",
    "    print(len(structure_t_more_list), len(structure_t_0_list), len(structure_t_1_list), len(structure_t_2_list), len(structure_t_3_list))\n",
    "    print(len(structure_joint_list), len(structure_joint_1_list), len(structure_joint_2_list), len(structure_joint_3_list))\n",
    "\n",
    "    if model == \"human\":\n",
    "        # probing_valid_rules_human(structure_d_list, type=\"Disjunctive\")\n",
    "        # probing_valid_rules_human(structure_t_more_list, type=\"Transitive-more\")\n",
    "        # probing_valid_rules_human(structure_joint_list, type=\"Transitive-Disjunctive\")\n",
    "        probing_valid_rules_human(structure_t_3_list, type=positive)\n",
    "    else:\n",
    "        # probing_both_valid_invalid_rules(structure_d_list, model=model, type=\"Disjunctive\", version=version)\n",
    "        # probing_both_valid_invalid_rules(structure_t_more_list, model=model, type=\"Transitive-more\", version=version)\n",
    "        # probing_both_valid_invalid_rules(structure_joint_list, model=model, type=\"Transitive-Disjunctive\", version=version)\n",
    "\n",
    "        probing_both_valid_invalid_rules(structure_t_3_list, model=model, type=positive, version=version, think_v=think_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "83 51 17 15 373\n",
      "109 49 34 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 660867.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human False 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_detailed_structure(\"human\", positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "83 51 17 15 438\n",
      "109 49 34 26\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [50:46<00:00, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 0\n",
      "GPT-4 False 105 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_detailed_structure(\"GPT-3.5\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-4\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-3.5-Instruct\", positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "206 141 35 20 666\n",
      "134 48 45 41\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [58:53<00:00, 23.56s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 0\n",
      "GPT-4 True 97 0.6466666666666666\n",
      "137\n",
      "206 141 35 20 666\n",
      "134 48 45 41\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [1:01:06<00:00, 24.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 0\n",
      "GPT-4 True 123 0.82\n",
      "137\n",
      "206 141 35 20 666\n",
      "134 48 45 41\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [53:43<00:00, 21.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 0\n",
      "GPT-4 True 107 0.7133333333333334\n",
      "137\n",
      "206 141 35 20 666\n",
      "134 48 45 41\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [52:11<00:00, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 0\n",
      "GPT-4 True 114 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_detailed_structure(\"GPT-3.5\", version=\"_v2\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-3.5\", version=\"_v3\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-3.5\", version=\"_v4\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-3.5\", version=\"_v5\", positive=True)\n",
    "\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v2\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v3\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v4\", positive=True)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v5\", positive=True)\n",
    "\n",
    "analysis_detailed_structure(\"GPT-3.5-Instruct\", version=\"_v2\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-3.5-Instruct\", version=\"_v3\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-3.5-Instruct\", version=\"_v4\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-3.5-Instruct\", version=\"_v5\", positive=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "83 51 17 15 438\n",
      "109 49 34 26\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [55:35<00:00, 22.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 0\n",
      "GPT-4 False 102 0.68\n",
      "181\n",
      "83 51 17 15 438\n",
      "109 49 34 26\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [48:54<00:00, 19.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 0\n",
      "GPT-4 False 118 0.7866666666666666\n",
      "181\n",
      "83 51 17 15 438\n",
      "109 49 34 26\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [43:35<00:00, 17.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 0\n",
      "GPT-4 False 111 0.74\n",
      "181\n",
      "83 51 17 15 438\n",
      "109 49 34 26\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [43:05<00:00, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 0\n",
      "GPT-4 False 113 0.7533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_detailed_structure(\"GPT-4\", version=\"_v2\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v3\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v4\", positive=False)\n",
    "analysis_detailed_structure(\"GPT-4\", version=\"_v5\", positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_accuracy(rules, model='GPT-4', version=\"\", think_v=\"\"):\n",
    "    assert os.path.exists(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json')\n",
    "    with open(f'ScriptData/Primitive/Analysis_data/annotations{version}/{model}.json', 'r') as r_f:\n",
    "        label_list = json.load(r_f)\n",
    "\n",
    "    random_seed = 234\n",
    "    random.seed(random_seed)\n",
    "    selected_index = random.sample(list(range(len(rules))), len(rules))\n",
    "    if len(rules) >= 150: \n",
    "        selected_index = selected_index[:150]\n",
    "\n",
    "    acc_num = 0\n",
    "    for i in selected_index:\n",
    "        assert think_v + rules[i]['s_rule'].strip() in label_list\n",
    "        acc_num += label_list[think_v + rules[i]['s_rule'].strip()]\n",
    "    return acc_num/len(selected_index)\n",
    "    \n",
    "\n",
    "def analysis_structure_alltogether(model='GPT-4', positive=True, think_v=\"\"):\n",
    "    all_data_file = 'ScriptData/Primitive/Analysis_data/high_quality_probing_data.json'\n",
    "    with open(all_data_file, 'r') as r_f:\n",
    "        all_data = json.load(r_f)\n",
    "\n",
    "    version = [\"\", \"_v2\", \"_v3\", \"_v4\", \"_v5\"]\n",
    "\n",
    "    structure_d_list = []\n",
    "    structure_t_0_list = []\n",
    "    structure_t_more_list = []\n",
    "    structure_t_1_list = []\n",
    "    structure_t_2_list = []\n",
    "    structure_t_3_list = []\n",
    "    structure_joint_list = []\n",
    "    structure_joint_1_list = []\n",
    "    structure_joint_2_list = []\n",
    "    structure_joint_3_list = []\n",
    "    for _ in range(len(all_data)):\n",
    "        if all_data[_]['positive'] == positive: # and all_data[_]['length'] > 1:\n",
    "            structure_t_3_list.append(all_data[_])\n",
    "\n",
    "            if all_data[_]['structure'] == \"disjunctive\":\n",
    "                structure_d_list.append(all_data[_])\n",
    "            elif all_data[_]['structure'] == \"transitive\" and all_data[_]['length'] > 1:\n",
    "                structure_t_more_list.append(all_data[_])\n",
    "                if all_data[_]['depth'] == 0:\n",
    "                    structure_t_0_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] >= 1 and all_data[_]['depth'] <= 3:\n",
    "                    if all_data[_]['depth'] == 1:\n",
    "                        structure_t_1_list.append(all_data[_])\n",
    "                    elif all_data[_]['depth'] == 2:\n",
    "                        structure_t_2_list.append(all_data[_])\n",
    "                    # else:\n",
    "                    #     structure_t_3_list.append(all_data[_])\n",
    "            elif all_data[_]['structure'] == \"transitive-disjunctive\":\n",
    "                structure_joint_list.append(all_data[_])\n",
    "                if all_data[_]['depth'] == 1:\n",
    "                    structure_joint_1_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] == 2:\n",
    "                    structure_joint_2_list.append(all_data[_])\n",
    "                elif all_data[_]['depth'] == 3:\n",
    "                    structure_joint_3_list.append(all_data[_])\n",
    "\n",
    "    all_acc_list = []\n",
    "    all_deviation_list = []\n",
    "    # for type in [\"Transitive\", \"Disjunctive\", \"Transitive-Disjunctive\"]: #\n",
    "    #     if type == \"Disjunctive\":\n",
    "    #         rules = structure_d_list\n",
    "    #     elif type == \"Transitive\":\n",
    "    #         rules = structure_t_more_list\n",
    "    #     else:\n",
    "    #         rules = structure_joint_list\n",
    "    for type in [\"Positive\"]: \n",
    "        rules = structure_t_3_list\n",
    "            \n",
    "        all_acc = []\n",
    "        for each_v in version:\n",
    "            cur_acc = get_accuracy(rules, model=model, version=each_v, think_v=think_v)\n",
    "            all_acc.append(cur_acc)\n",
    "        avg_acc = sum(all_acc)/len(all_acc)\n",
    "        deviation = np.std(all_acc)\n",
    "        \n",
    "        all_acc_list.append(round(avg_acc, 3))\n",
    "        all_deviation_list.append(round(deviation, 3))\n",
    "    print(all_acc_list)\n",
    "    print(all_deviation_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.851]\n",
      "[0.041]\n",
      "[0.809]\n",
      "[0.033]\n",
      "[0.661]\n",
      "[0.174]\n"
     ]
    }
   ],
   "source": [
    "analysis_structure_alltogether(\"GPT-4\")\n",
    "analysis_structure_alltogether(\"GPT-3.5\")\n",
    "analysis_structure_alltogether(\"GPT-3.5-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.787]\n",
      "[0.035]\n",
      "[0.808]\n",
      "[0.037]\n",
      "[0.539]\n",
      "[0.193]\n"
     ]
    }
   ],
   "source": [
    "analysis_structure_alltogether(\"GPT-4\", positive=False)\n",
    "analysis_structure_alltogether(\"GPT-3.5\", positive=False)\n",
    "analysis_structure_alltogether(\"GPT-3.5-Instruct\", positive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.787]\n",
      "[0.035]\n"
     ]
    }
   ],
   "source": [
    "analysis_structure_alltogether(\"GPT-4\", positive=False)\n",
    "analysis_structure_alltogether(\"GPT-3.5\", positive=False)\n",
    "analysis_structure_alltogether(\"GPT-3.5-Instruct\", positive=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78e48a7539a3cb4c61f94c606d308a5205252ec1cba00f52b696918ed6d3e76e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
